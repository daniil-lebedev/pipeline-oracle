name: "Pipeline Oracle Analysis"
description: "Analyzes failed workflows, runs AI analysis on logs, and creates a GitHub issue with the report."
author: "Daniil Lebedev daniilwork247@gmail.com"

branding:
  icon: "zap"
  color: "blue"

inputs:
  workflow-to-track:
    description: "Name of the workflow to track (e.g., 'Deploying to Prod')."
    required: false
    default: "Deploying to Prod"
  openai-api-key:
    description: "OpenAI API key for AI analysis."
    required: true
  create-github-issue:
    description: "Flag to create or not create a GitHub issue from the report. Y or N."
    required: true

runs:
  using: "composite"
  steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ github.token }}

    - name: Fetch logs from last failed workflow
      id: fetch_logs
      shell: bash
      run: |
        echo "[INFO] Fetching last failed workflow..."
        RUN_ID=$(gh run list --limit 5 --json databaseId,name,conclusion \
          --jq "[.[] | select(.conclusion == \"failure\" and .name != \"Pipeline Oracle Analysis\")][0].databaseId")
        if [ -z "$RUN_ID" ]; then
          echo "[ERROR] No failed workflows found. Exiting." >&2
          exit 1
        fi
        echo "[INFO] Last failed workflow ID: $RUN_ID"
        mkdir -p logs
        echo "[INFO] Fetching logs for run $RUN_ID..."
        gh run view "$RUN_ID" --log > logs/full_log.txt || { echo "[ERROR] Could not fetch logs"; exit 1; }
        echo "[INFO] Log file (first 20 lines):"
        head -20 logs/full_log.txt || { echo "[WARNING] Log file is empty"; }
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up Python and install dependencies
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install Python dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run AI Analysis on Execution Logs
      shell: bash
      run: python pipeline-oracle.py || { echo "[ERROR] AI analysis failed"; exit 1; }
      env:
        OPENAI_API_KEY: ${{ inputs.openai-api-key }}

    - name: Prepend commit message to analysis report
      shell: bash
      run: |
        COMMIT_MSG="${{ github.event.workflow_run.head_commit.message }}"
        echo "# Report Analysis: $COMMIT_MSG" > tmp_report.md
        echo "" >> tmp_report.md
        cat analysis_report.md >> tmp_report.md
        mv tmp_report.md analysis_report.md

    - name: Upload analysis report as artifact
      uses: actions/upload-artifact@v4
      with:
        name: failure-analysis-report
        path: |
          analysis_report.md
          logs/full_log.txt
        if-no-files-found: warn

    - name: Clean up logs directory
      shell: bash
      run: rm -rf logs

    - name: Create a GitHub Actions Summary using Report
      shell: bash
      run: cat analysis_report.md >> $GITHUB_STEP_SUMMARY

    - name: Create GitHub Issue with AI Analysis
      if: ${{ inputs.create-github-issue == 'Y' || inputs.create-github-issue == 'y' }}
      uses: peter-evans/create-issue-from-file@v4
      with:
        token: ${{ github.token }}
        title: "Pipeline Oracle Report: ${{ github.event.workflow_run.head_commit.message }}"
        content-filepath: analysis_report.md
        assignees: ${{ github.event.workflow_run.actor.login }}
        labels: |
          ci-failure
          analysis