name: "Pipeline Oracle Analysis"
description: "Analyzes failed jobs and steps, runs AI analysis, and optionally creates a GitHub issue with the report."
author: "Daniil Lebedev daniilwork247@gmail.com"

branding:
  icon: "zap"
  color: "blue"

inputs:
  workflow-to-track:
    description: "Name of the workflow to track (e.g., 'Deploying to Prod')."
    required: false
    default: "Deploying to Prod"
  openai-api-key:
    description: "OpenAI API key for AI analysis."
    required: true
  create-github-issue:
    description: "Flag to create a GitHub issue from the report. Y or N."
    required: false
    default: "N"
  python-version:
    description: "Python version to use for analysis."
    required: false
    default: "3.10"
  max-log-lines:
    description: "Maximum number of log lines to analyze."
    required: false
    default: "200"
  max-log-size:
    description: "Maximum characters to send to AI."
    required: false
    default: "10000"
  ai-model:
    description: "AI model to use for analysis."
    required: false
    default: "gpt-4-turbo"
  ai-base-url:
    description: "Base URL for AI API (optional)."
    required: false
    default: "https://api.openai.com/v1"

runs:
  using: "composite"
  steps:
    - name: Cache GitHub CLI
      uses: actions/cache@v4
      with:
        path: /usr/local/bin/gh
        key: ${{ runner.os }}-gh-cli-v2
        restore-keys: |
          ${{ runner.os }}-gh-cli-
      env:
        GH_TOKEN: ${{ github.token }}

    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ github.token }}

    - name: Fetch logs from last failed workflow
      id: fetch_logs
      shell: bash
      run: |
        echo "[INFO] Fetching last failed workflow..."
        RUN_ID=""
        for i in {1..3}; do
          RUN_ID=$(gh run list \
            --workflow "${{ inputs.workflow-to-track }}" \
            --limit 5 \
            --json databaseId,name,conclusion \
            --jq "[.[] | select(.conclusion == \"failure\" and .name != \"Pipeline Oracle Analysis\")][0].databaseId") && break || sleep 10
        done
        
        if [ -z "$RUN_ID" ]; then
          echo "[ERROR] No failed workflows found. Exiting."
          exit 1
        fi
        
        echo "[INFO] Last failed workflow ID: $RUN_ID"
        mkdir -p logs

        echo "[INFO] Fetching jobs for workflow run..."
        JOB_IDS=$(gh run view "$RUN_ID" --json jobs --jq '.jobs | map(select(.conclusion == "failure")) | .[].jobId')
        
        if [ -z "$JOB_IDS" ]; then
          echo "[ERROR] No failed jobs found in this workflow."
          exit 1
        fi

        echo "[INFO] Fetching logs for failed jobs..."
        for JOB_ID in $JOB_IDS; do
          gh run view "$JOB_ID" --log > "logs/job_${JOB_ID}.txt" || echo "[WARNING] Could not fetch logs for job $JOB_ID"
          FAILED_STEPS=$(gh run view "$JOB_ID" --json steps --jq ".steps | map(select(.conclusion == \"failure\")) | .[].name")
          echo "[INFO] Failed steps for job $JOB_ID: $FAILED_STEPS"
        done

      env:
        GH_TOKEN: ${{ github.token }}

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ inputs.python-version }}
        cache: 'pip'

    - name: Install Python dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt --no-cache-dir

    - name: Check if `pipeline-oracle.py` exists
      shell: bash
      run: |
        if [[ ! -f pipeline-oracle.py ]]; then
          echo "[ERROR] pipeline-oracle.py not found. Exiting."
          exit 1
        fi

    - name: Run AI Analysis on Failed Steps
      shell: bash
      run: |
        echo "[INFO] Running AI Analysis..."
        python pipeline-oracle.py || { echo "[ERROR] AI analysis failed"; exit 1; }
      env:
        OPENAI_API_KEY: ${{ inputs.openai-api-key }}
        OPENAI_MODEL: ${{ inputs.ai-model }}
        OPENAI_BASE_URL: ${{ inputs.ai-base-url }}
        MAX_LOG_LINES: ${{ inputs.max-log-lines }}
        MAX_LOG_SIZE: ${{ inputs.max-log-size }}

    - name: Prepend commit message to analysis report
      shell: bash
      run: |
        COMMIT_MSG="${{ github.event.workflow_run.head_commit.message }}"
        echo "# Report Analysis: $COMMIT_MSG" > tmp_report.md
        echo "" >> tmp_report.md
        cat analysis_report.md >> tmp_report.md
        mv tmp_report.md analysis_report.md

    - name: Compress and Upload Analysis Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: failure-analysis-report
        path: |
          analysis_report.md
          logs/*.txt
        compression-level: 9
        if-no-files-found: warn

    - name: Clean up logs directory
      shell: bash
      run: rm -rf logs

    - name: Create a GitHub Actions Summary using Report
      shell: bash
      run: cat analysis_report.md >> $GITHUB_STEP_SUMMARY
